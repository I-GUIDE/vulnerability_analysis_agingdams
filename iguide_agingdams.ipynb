{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a533d459-d358-49c3-b0b5-4c22aca0cb6c",
   "metadata": {},
   "source": [
    "<img src=\"statics/iguide_logo.png\" width=200 height=200 />\n",
    "\n",
    "# Assessing social vulnerability to the aging dam infrastructure in the US"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72103e9-d041-4bdb-b14b-2961588fe3ca",
   "metadata": {},
   "source": [
    "<h4 style=\"color:red;\"> Note: Some cells require User Interaction; \"Run cell-by-cell\" is recommended; \"Run All\" will not work. </h4>\n",
    "\n",
    "This notebook demonstrates how the **first** and the **second** steps of the abstract below, focusing on a single dam (Barker Dam in Houston, TX).\n",
    "\n",
    "**Abstract**: This study aims to address the questions of whether and where socioeconomically disadvantaged populations are vulnerable to disasters caused by potential failures of aging dams by analyzing 427 federal dams in the conterminous US. Our analysis is designed to include the following three steps. First, we identified census tracts inundated from flooding caused by a dam failure in a worst-case scenario: Maximum High (MH)-Breach. Second, we utilized a *t-test* to investigate whether inundated census tracts have higher social vulnerability than non-inundated ones. In this context, we employed seven census variables based on a widely adopted social vulnerability index: no high school diploma, population below poverty level, not fluent in English, mobile home residents, no vehicle households, unemployment rate, and people aged over 65. Third, we conducted *k-means clustering* to dams based on the t-score of each of the seven variables. Our preliminary results show that the dams are classified into three categories based on the populations that might be impacted by potential dam failures: 1) socioeconomically disadvantaged populations (i.e., no high school diploma, poverty, not fluent in English, no vehicle, and unemployment), populations without particular socioeconomic advantages or disadvantages, and 3) populations with both socioeconomic advantages (i.e., fluent in English) and disadvantages (i.e., mobile home residents and older people). Our investigation of locations of the dams reveals that most dams potentially impacting socioeconomically disadvantaged populations are in California, Colorado, New Mexico, New Hampshire, and Massachusetts.\n",
    "\n",
    "The orginal workflow is composed of data retrieval from multiple sources, a series of spatial operations on raster and vector datasets, statistical analysis and visualization. The computational bottleneck started arising in data retrieval and became roadblocks in spatial operations when some large dams were being processed. The I-GUIDE platform offers a solution by moving both data retrieval and spatial operations to reusable GeoEDF connectors and processors implenmented within the CyberGIS-Compute service, which hands over the resource-intensive tasks to HPC for execution. Therfore, the same workflow can be repeated and applied to all the 427 dams of interest upscaling the research to national scale.\n",
    "\n",
    "The proposed I-GUIDE workflow to support this research is shown below. \n",
    "<center><img src=\"statics/agingdam.png\" width=\"800\" height=\"600\" /></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957cb8c0-eb30-4bc7-a121-0a834cdbfcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import pygeos\n",
    "import zipfile\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import display, HTML # for display warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1868af2-74ab-4706-8a56-ddca9a7cd886",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define a dam of focus\n",
    "Please provide a `dam_id` from <a herf=\"https://nid.usace.army.mil/#/\">**National Inventory of Dams (NID)**</a> to examine its social vulnerabilty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cacf6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dam_id = 'TX00019' # Dam ID from National Inventory of Dams\n",
    "scenarios = 'MH Breach' # Maximum-High Breach. There are several senario available, such as NH Breach (Normal High Breach)\n",
    "\n",
    "params_flood_inundation = {\"dam_id\": dam_id, \"scenarios\": scenarios} \n",
    "params_flood_inundation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293edf59-fa23-4835-82ab-f7fe71e7d974",
   "metadata": {},
   "source": [
    "## Step 0: Download Flood Inundation Map for the chosen Dam\n",
    "\n",
    "This step will retrieve the inundation map of a dam from the NID database into the I-GUIDE Platform repository with the provided `dam_id` and `scenarios`. \n",
    "from the MID database into the I-GUIDE Platform repository. \n",
    "\n",
    "CyberGIS-Compute will be excuted when you run the cell below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0eeaff-8099-4c08-bb58-71576930e4a6",
   "metadata": {},
   "source": [
    "<h4 style=\"color:red;\"> User Interaction Required </h4>\n",
    "\n",
    "- Run the cell below \n",
    "- Click on \"Submit Job\" on the \"Your Job Status\" tabpage \n",
    "- Wait until Job is finished (2-5 mins)\n",
    "- Proceed to the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba8ad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cybergis_compute_client\n",
    "from cybergis_compute_client import CyberGISCompute\n",
    "\n",
    "cybergis = CyberGISCompute(url=\"cgjobsup.cigi.illinois.edu\", isJupyter=True, protocol=\"HTTPS\", port=443, suffix=\"v2\")\n",
    "cybergis.show_ui(defaultJob=\"Dam_Flood_Inundation_Map_Connector\",input_params=params_flood_inundation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f929809-4c63-45c9-910f-f51eda866ac2",
   "metadata": {},
   "source": [
    "Retain the job ID of CyberGIS-Compute for further analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ae01ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_dam_fim_connector = cybergis.job\n",
    "floodmap_path_HPC = \"{}\".format(job_dam_fim_connector.id)\n",
    "params_classify_tracts = {\"floodmap_path\": floodmap_path_HPC} \n",
    "params_classify_tracts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734e2c4f-c6c7-44e4-a918-09ccd1960316",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step1: Extract Inundation Classification for Census Tracts for this Dam\n",
    "\n",
    "The following cell will execute the first step of the analysis (identifying the inundated and non-inundated areas of a dam failure) on the I-GUIDE Platform. This process consists of three steps. This step will provide a CSV file with the list of census tract GEOID and whether they are inundated or not. <br>\n",
    "**Note:** You **do need** to download the result file before executing the later cells. \n",
    "\n",
    "- Downsample the original inundation map to 10mx10m and vectorize the raster inundation map into polygons. \n",
    "- Identify inundated census tracts of a dam failure by finding the intersection between census tracts and the inundation polygons.\n",
    "- Define non-inundated census tracts (10-km buffer from the river associated with the flood event). This area will be used to collect the benchmark of social vulnerability to the ones of inundated census tracts.\n",
    "\n",
    "<center><img src=\"statics/step1.png\" width=\"400\" height=\"600\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63abd3dc-261b-47a1-a363-68a33b5a1da8",
   "metadata": {},
   "source": [
    "<h4 style=\"color:red;\"> User Interaction Required </h4>\n",
    "\n",
    "- Run the cell below \n",
    "- Click on \"Submit Job\" on the \"Your Job Status\" tabpage \n",
    "- Wait until Job is finished (3-6 mins)\n",
    "- Switch to \"Download Job Result\" tabpage\n",
    "- Choose \"/\" and click on Download\n",
    "- Wait until downloading is finished\n",
    "- Proceed to the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bd3436-1624-4fcb-a02c-4f5554acacb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cybergis_compute_client\n",
    "from cybergis_compute_client import CyberGISCompute\n",
    "\n",
    "cybergis = CyberGISCompute(url=\"cgjobsup.cigi.illinois.edu\", isJupyter=True, protocol=\"HTTPS\", port=443, suffix=\"v2\")\n",
    "cybergis.show_ui(defaultJob=\"Extract_Inundation_Census_Tracts_Processor\",input_params=params_classify_tracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f247131-0fb4-4f9e-9b1b-2fb3b822bd7c",
   "metadata": {},
   "source": [
    "Identify the location of the output dataset for use in further analysis and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007fb7a7-44af-4002-928a-2f5fdd21f04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_census_tracts = cybergis.recentDownloadPath\n",
    "census_tracts_csvfile = '{}/census_tracts.csv'.format(output_census_tracts)\n",
    "census_tracts_csvfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88e42ed-3679-4988-869d-8815322aaf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(os.path.join(census_tracts_csvfile)):\n",
    "    display(HTML('<h4 style=\"color:red;\">It appears you did not download the job results per instruction above, please double check!</h4>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba841574-05d3-48cf-ae16-2b589508cfc3",
   "metadata": {},
   "source": [
    "### Process the job output of the step 1\n",
    "\n",
    "This cell will read the result of the first task and format the GEOID of census tracts. There is a known issue with CSV files that they lose the first character of numerical values if it starts with '0'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cccd065-70ad-45c8-8db5-98e64a26d1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the result file of the first task\n",
    "inund_tract = pd.read_csv(census_tracts_csvfile)\n",
    "inund_tract['GEOID'] = inund_tract['GEOID'].astype(str)\n",
    "inund_tract['str_length'] = inund_tract.apply(lambda x:len(x['GEOID']), axis=1)\n",
    "\n",
    "# If the GEOID doesn't have a length of 11, enter '0' to its first character. \n",
    "inund_tract['GEOID'] = inund_tract.apply(lambda x: '0' + x['GEOID'] if x['str_length'] == 10 else x['GEOID'], axis=1)\n",
    "inund_tract = inund_tract.groupby(['Dam_ID', 'Scenario', 'GEOID'], \n",
    "                                  group_keys=False).apply(lambda x:x.loc[x['Class'].idxmax()]\n",
    "                                                         ).reset_index(drop=True)\n",
    "\n",
    "# List of states that is associated with the dam failure\n",
    "state_list = inund_tract.apply(lambda x:x['GEOID'][0:2], axis=1).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443c730a-481a-4995-a910-556e58b3d488",
   "metadata": {},
   "source": [
    "## Step2: Compare social vulnerability of census tracts\n",
    "\n",
    "This step investigates whether inundated census tracts have higher social vulnerability than non-inundated ones. It consists of the following two sub-steps. \n",
    "\n",
    "- Retrieve seven census data related to social vulnerability (no high school diploma, population below poverty level, not fluent in English, mobile home residents, no vehicle households, unemployment rate, and people aged over 65)\n",
    "- Conduct a t-test to see if the inundated census tracts have a different mean of census data compared to the non-inundated ones. \n",
    "\n",
    "<center><img src=\"statics/step2.png\" width=\"400\" height=\"600\" /></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286bfbd8-2824-4357-9912-f74ca80be5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip geographical units file\n",
    "with zipfile.ZipFile('./census_tract_from_api.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('.')\n",
    "    \n",
    "# Import geographical units\n",
    "tract_geom = gpd.read_file('./census_tract_from_api.geojson')\n",
    "tract_geom = tract_geom.loc[tract_geom['STATE'].isin(state_list)].reset_index()\n",
    "\n",
    "# Import list of dams\n",
    "fed_dams = requests.get('https://fim.sec.usace.army.mil/ci/fim/getAllEAPStructure').json()\n",
    "fed_dams = pd.DataFrame(fed_dams)\n",
    "fed_dams = gpd.GeoDataFrame(fed_dams, geometry=gpd.points_from_xy(fed_dams['LON'], fed_dams['LAT'], crs=\"EPSG:4326\"))\n",
    "fed_dams = fed_dams.loc[fed_dams['ID'].isin(inund_tract['Dam_ID'])]\n",
    "print(fed_dams.shape[0])\n",
    "fed_dams.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16e3ede-e222-474d-a207-3de9b6f5896e",
   "metadata": {},
   "source": [
    "Define the functions to retrieve social vulnerability related census data from the census API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe624ec-eb01-4ef6-a6c0-1a0f5b42348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_census_table(state_list, table, key):\n",
    "    \n",
    "    result_df = pd.DataFrame()\n",
    "    \n",
    "    # querying at census tract level. There are different URLs for different tables per the category if census data.\n",
    "    for state in tqdm(state_list):\n",
    "        if table.startswith('group'):\n",
    "            address = f'https://api.census.gov/data/2020/acs/acs5?get=NAME,{table}&for=tract:*&in=state:{state}&in=county:*'\n",
    "        elif table.startswith('DP'):\n",
    "            address = f'https://api.census.gov/data/2020/acs/acs5/profile?get=NAME,{table}&for=tract:*&in=state:{state}&in=county:*'\n",
    "        elif table.startswith('S'):\n",
    "            address = f'https://api.census.gov/data/2020/acs/acs5/subject?get=NAME,{table}&for=tract:*&in=state:{state}&in=county:*'\n",
    "        response = requests.get(f'{address}&key={key}').json()\n",
    "        result_ = pd.DataFrame(response)\n",
    "        \n",
    "        result_.columns = response[0]\n",
    "        result_.drop(0, axis=0, inplace=True)\n",
    "        \n",
    "        if table.startswith('group'):\n",
    "            result_.drop(['NAME', 'state', 'county', 'tract'], axis=1, inplace=True) \n",
    "        else:\n",
    "            result_.drop(['NAME'], axis=1, inplace=True) # When querying tract level data\n",
    "        \n",
    "        result_df = pd.concat([result_, result_df]).reset_index(drop=True)\n",
    "        \n",
    "    return result_df\n",
    "\n",
    "def merge_census_data_into_inund_tract(inund_gdf, table, attr_name):\n",
    "    census_table = call_census_table(state_list, table, key)\n",
    "    \n",
    "    if 'GEO_ID' in census_table.columns:\n",
    "        census_table['GEO_ID'] = census_table.apply(lambda x:x['GEO_ID'][9:], axis=1)\n",
    "        census_table['GEO_ID'] = census_table['GEO_ID'].astype(str)\n",
    "        census_table = census_table.rename(columns={'GEO_ID': 'GEOID'})\n",
    "    else:\n",
    "        census_table['GEOID'] = census_table.apply(lambda x:x['state'] + x['county'] + x ['tract'], axis=1)\n",
    "    \n",
    "    if table == 'group(B06009)': # No high school diploma: Persons (age 25+) with no high school diploma \n",
    "        census_table[attr_name] = census_table.apply(lambda x:round(int(x['B06009_002E']) / int(x['B06009_001E']) * 100) \n",
    "                                                     if int(x['B06009_001E']) != 0 else 0, axis=1)\n",
    "    elif table == 'group(B17001)': # Poverty: persons below poverty estimate (not available at bg level)\n",
    "        census_table[attr_name] = census_table.apply(lambda x:round(int(x['B17001_002E']) / int(x['B17001_001E']) * 100) \n",
    "                                                     if int(x['B17001_001E']) != 0 else 0, axis=1)\n",
    "    elif table == 'group(B16005)': # Not proficient English: \"NATIVITY BY LANGUAGE SPOKEN AT HOME BY ABILITY TO SPEAK ENGLISH FOR THE POPULATION 5 YEARS AND OVER\"\n",
    "        census_table[attr_name] = census_table.apply(lambda x:round((int(x['B16005_007E']) + int(x['B16005_008E']) +\n",
    "                                                                     int(x['B16005_012E']) + int(x['B16005_013E']) + \n",
    "                                                                     int(x['B16005_017E']) + int(x['B16005_018E']) + \n",
    "                                                                     int(x['B16005_022E']) + int(x['B16005_023E']) + \n",
    "                                                                     int(x['B16005_029E']) + int(x['B16005_030E']) + \n",
    "                                                                     int(x['B16005_034E']) + int(x['B16005_035E']) + \n",
    "                                                                     int(x['B16005_039E']) + int(x['B16005_040E']) + \n",
    "                                                                     int(x['B16005_044E']) + int(x['B16005_045E'])) \n",
    "                                                                    / int(x['B16005_001E']) * 100) \n",
    "                                                     if int(x['B16005_001E']) != 0 else 0, axis=1)\n",
    "    else:\n",
    "        census_table.rename(columns={table: attr_name}, inplace=True)\n",
    "        if census_table[attr_name].dtype == 'O':\n",
    "            census_table[attr_name] = census_table[attr_name].astype(float)\n",
    "    \n",
    "    inund_gdf = inund_gdf.merge(census_table[['GEOID', attr_name]], on='GEOID')\n",
    "    \n",
    "    return inund_gdf\n",
    "\n",
    "# API key for census API\n",
    "key = 'fbcac1c2cc26d853b42c4674adf905e742d1cb2b'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f031c5-0119-447c-8eb4-8660e18f20f6",
   "metadata": {},
   "source": [
    "Querying seven census data that are associated with social vulnerability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767b88b7-44c7-49aa-8025-1e58c73051e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of people over 25 without high school diploma\n",
    "inund_tract = merge_census_data_into_inund_tract(inund_tract, 'group(B06009)', 'no_diploma')\n",
    "# Percentage of people below the poverty level\n",
    "inund_tract = merge_census_data_into_inund_tract(inund_tract, 'group(B17001)', 'poverty')\n",
    "# Percentage of resident with no proficient English\n",
    "inund_tract = merge_census_data_into_inund_tract(inund_tract, 'group(B16005)', 'less_english')\n",
    "# Percentage of mobile homes estimate\n",
    "inund_tract = merge_census_data_into_inund_tract(inund_tract, 'DP04_0014PE', 'mobile_home') \n",
    "# Percentage of housholds without vehicle available\n",
    "inund_tract = merge_census_data_into_inund_tract(inund_tract, 'DP04_0058PE', 'no_vehicle') \n",
    "# Unemployment Rate estimate\n",
    "# The ACS calculated Unemployment Rate = E_UNEMP / civilian population age 16 + in the labor force\n",
    "inund_tract = merge_census_data_into_inund_tract(inund_tract, 'DP03_0009PE', 'unemployment') \n",
    "# Percentage of person aged 65 and older estimate\n",
    "inund_tract = merge_census_data_into_inund_tract(inund_tract, 'S0101_C02_030E', 'age65') \n",
    "inund_tract.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae48073-b355-47f2-9d70-d4ccb650316e",
   "metadata": {},
   "source": [
    "Define a function to compare the mean of census data depending on the inundation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b645e9-4d42-431d-96f7-0a74465fe66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_vulnerabilty(inund_gdf, attr_name, dam_gdf):\n",
    "    \n",
    "    for dam_id in tqdm(inund_gdf['Dam_ID'].unique()):\n",
    "        \n",
    "        # Divide the inundated census tract of each dam into two classes (inundated area and not inundated area)\n",
    "        dam_inund_area = inund_gdf.loc[(inund_gdf['Class'] > 0) & (inund_gdf['Dam_ID'] == dam_id)]\n",
    "        dam_not_inund_area = inund_gdf.loc[(inund_gdf['Class'] == 0) & (inund_gdf['Dam_ID'] == dam_id)]\n",
    "        \n",
    "        # Conduct t-test to see the inundated area has more vulnerability in each attribute\n",
    "        if attr_name in ['mobile_home', 'no_vehicle', 'unemployment', 'age65']:\n",
    "            val_x = dam_inund_area.loc[dam_inund_area[attr_name] != -666666666, attr_name]\n",
    "            val_y = dam_not_inund_area.loc[dam_not_inund_area[attr_name] != -666666666, attr_name]\n",
    "        else:\n",
    "            val_x = dam_inund_area[attr_name]\n",
    "            val_y = dam_not_inund_area[attr_name]\n",
    "        \n",
    "        t_test = stats.ttest_ind(val_x, val_y)\n",
    "        \n",
    "        dam_gdf.loc[dam_gdf['ID'] == dam_id, 't_'+ attr_name] = t_test[0] # t score\n",
    "        dam_gdf.loc[dam_gdf['ID'] == dam_id, 'p_'+ attr_name] = t_test[1] # p value\n",
    "        \n",
    "        # If inundated area has higher mean of census data than non-inundated area and the t-test is significant\n",
    "        if (t_test[1] < 0.05) & (t_test[0] > 0):\n",
    "            dam_gdf.loc[dam_gdf['ID'] == dam_id, 'c_'+ attr_name] = 'P' \n",
    "        \n",
    "        # If inundated area has lower mean of census data than non-inundated area and the t-test is significant\n",
    "        elif (t_test[1] < 0.05) & (t_test[0] < 0):\n",
    "            dam_gdf.loc[dam_gdf['ID'] == dam_id, 'c_'+ attr_name] = 'N' \n",
    "        \n",
    "        # If the t-test is not statistically significant\n",
    "        else:\n",
    "            dam_gdf.loc[dam_gdf['ID'] == dam_id, 'c_'+ attr_name] = 'NA' \n",
    "    \n",
    "    return dam_gdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df574f32-5ead-4ea0-930f-abc555221970",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_list = ['no_diploma', 'poverty', 'no_vehicle', 'unemployment', 'less_english', 'mobile_home',  'age65']\n",
    "\n",
    "# Conduct t-test for each census data\n",
    "for attr in attr_list:\n",
    "    fed_dams = compare_vulnerabilty(inund_tract, attr, fed_dams)\n",
    "fed_dams = fed_dams.loc[~fed_dams['t_no_diploma'].isna()] # Remove null values that are caused by incomplete t-test\n",
    "fed_dams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5589e492-cacd-47ff-95dc-2393345b92f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Visualization of Social Vulnerabilty near Barker Dam, Houston, TX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcf97ae-1eaa-4b94-92f5-9b075bc91374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vulnerability_attribute_around_dam(dam_id):\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(30,12))\n",
    "    ax = axes.reshape(-1)\n",
    "\n",
    "    # Define geography related to each dam\n",
    "    dam_area = inund_tract_geom.loc[inund_tract_geom['Dam_ID'] == dam_id].reset_index()\n",
    "    scene = dam_area.loc[0, 'Scenario']\n",
    "\n",
    "    benchmark_area = dam_area.loc[dam_area['Class'] == 0]\n",
    "    inund_area = dam_area.loc[dam_area['Class'] > 0]\n",
    "    benchmark_area_union = benchmark_area.dissolve(by='Dam_ID')\n",
    "    inund_area_union = inund_area.dissolve(by='Dam_ID')\n",
    "\n",
    "    fed_dams_focus = fed_dams.loc[fed_dams['ID'] == dam_id].reset_index()\n",
    "\n",
    "    # Plot maps\n",
    "    var_list = ['no_diploma', 'poverty', 'less_english', 'mobile_home', 'no_vehicle', 'unemployment', 'age65']\n",
    "    for m in range(8):\n",
    "        if m == 0:\n",
    "            fed_dams_focus.plot(ax=ax[m], markersize=500, color='black')\n",
    "            ax[m].set_title(label=\"Inundated Area\", fontsize=24)\n",
    "        else:\n",
    "            dam_area.loc[dam_area[var_list[m-1]] != -666666666].plot(var_list[m-1], ax=ax[m], scheme='FisherJenks', cmap='Reds')\n",
    "            dam_area.loc[dam_area[var_list[m-1]] == -666666666].plot(ax=ax[m], color='Grey')\n",
    "            ax[m].set_title(label=f\"{var_list[m-1]} ({fed_dams_focus['c_' + var_list[m-1]].values[0]})\", fontsize=24)\n",
    "\n",
    "        benchmark_area_union.boundary.plot(ax=ax[m], color='black', lw=0.5, linestyle='dashed')\n",
    "        inund_area_union.boundary.plot(ax=ax[m], color='black', lw=1)\n",
    "        ax[m].get_xaxis().set_visible(False)\n",
    "        ax[m].get_yaxis().set_visible(False)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b247e6-dfdf-4ac3-a375-4dd15683516f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign geometry to census tracts\n",
    "inund_tract_geom = inund_tract.merge(tract_geom[['GEOID', 'geometry']], on='GEOID')\n",
    "inund_tract_geom = gpd.GeoDataFrame(inund_tract_geom, geometry=inund_tract_geom['geometry'], crs='EPSG:4326')\n",
    "inund_tract_geom.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59579817-052b-4c39-b616-cec1115f05d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dam_id in fed_dams['ID'].unique():\n",
    "    plot_vulnerability_attribute_around_dam(dam_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e221c623-fa14-4c42-8052-f58b0abf7c56",
   "metadata": {},
   "source": [
    "## The End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:iguide]",
   "language": "python",
   "name": "conda-env-iguide-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
